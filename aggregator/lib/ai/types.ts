import type { FeedItem } from '../types/feed'

/**
 * Supported AI/LLM providers
 */
export type AIProvider = 'openai' | 'anthropic' | 'local' | 'mock'

/**
 * AI model configuration
 */
export interface AIModelConfig {
  provider: AIProvider
  model: string
  apiKey?: string
  baseUrl?: string
  maxTokens?: number
  temperature?: number
  timeout?: number
}

/**
 * AI processing request
 */
export interface AIRequest {
  prompt: string
  content: string
  maxTokens?: number
  temperature?: number
  model?: string
}

/**
 * AI processing response
 */
export interface AIResponse {
  content: string
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
  model: string
  provider: AIProvider
  duration: number
}

/**
 * Content summary generated by AI
 */
export interface ContentSummary {
  summary: string
  keyPoints: string[]
  relevanceScore?: number
  tags: string[]
  insights?: string[]
  confidence: number
  processingTime: number
}

/**
 * Enhanced feed item with AI processing
 */
export interface EnhancedFeedItem extends FeedItem {
  aiSummary?: ContentSummary
  aiTags?: string[]
  aiInsights?: string[]
  semanticScore?: number
  processingMetadata?: {
    provider: AIProvider
    model: string
    processingTime: number
    confidence: number
  }
}

/**
 * AI processing options
 */
export interface AIProcessingOptions {
  generateSummary: boolean
  enhanceTags: boolean
  extractInsights: boolean
  calculateSemanticScore: boolean
  maxConcurrency: number
  timeout: number
  fallbackProvider?: AIProvider
}

/**
 * AI provider interface
 */
export interface AIProvider_Interface {
  readonly name: AIProvider
  readonly supportedModels: string[]
  
  /**
   * Initialize the provider with configuration
   */
  initialize(config: AIModelConfig): Promise<void>
  
  /**
   * Check if the provider is ready/configured
   */
  isReady(): boolean
  
  /**
   * Process an AI request
   */
  processRequest(request: AIRequest): Promise<AIResponse>
  
  /**
   * Generate content summary
   */
  generateSummary(content: string, focusArea?: string): Promise<ContentSummary>
  
  /**
   * Calculate semantic relevance score
   */
  calculateSemanticRelevance(content: string, focusDescription: string): Promise<number>
  
  /**
   * Generate enhanced tags
   */
  generateTags(content: string, existingTags: string[]): Promise<string[]>
  
  /**
   * Extract key insights
   */
  extractInsights(content: string, focusArea?: string): Promise<string[]>
}

/**
 * Batch processing result
 */
export interface BatchProcessingResult {
  processed: EnhancedFeedItem[]
  failed: Array<{
    item: FeedItem
    error: string
  }>
  stats: {
    totalItems: number
    successfulItems: number
    failedItems: number
    totalProcessingTime: number
    averageProcessingTime: number
    totalTokensUsed: number
    totalCost?: number
  }
}